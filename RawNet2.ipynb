{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc740ed-854d-4b77-94c5-3fbf6d5cf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RawNet2 Implementation for Audio Deepfake Detection\n",
    "# Part 2 of Momenta Assessment\n",
    "# Integrates provided RawNet model and ASVDataset for ASVspoof 5\n",
    "\n",
    "# ## 1. Setup\n",
    "# Install dependencies and import libraries\n",
    "\n",
    "!pip install torch torchvision torchaudio librosa numpy matplotlib tensorboardX pyyaml soundfile joblib\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import yaml\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import collections\n",
    "import soundfile as sf\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ## 2. Model Definition\n",
    "# RawNet (RawNet2 variant) from provided code\n",
    "\n",
    "class SincConv(nn.Module):\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, device, out_channels, kernel_size, in_channels=1, sample_rate=16000,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, groups=1, freq_scale='Mel'):\n",
    "        super(SincConv, self).__init__()\n",
    "        if in_channels != 1:\n",
    "            raise ValueError(f\"SincConv only supports one input channel (here, in_channels = {in_channels})\")\n",
    "        \n",
    "        self.out_channels = out_channels + 1\n",
    "        self.kernel_size = kernel_size if kernel_size % 2 else kernel_size + 1\n",
    "        self.sample_rate = sample_rate\n",
    "        self.device = device\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        \n",
    "        if bias:\n",
    "            raise ValueError('SincConv does not support bias.')\n",
    "        if groups > 1:\n",
    "            raise ValueError('SincConv does not support groups.')\n",
    "        \n",
    "        NFFT = 512\n",
    "        f = int(self.sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n",
    "        if freq_scale == 'Mel':\n",
    "            fmel = self.to_mel(f)\n",
    "            fmelmax, fmelmin = np.max(fmel), np.min(fmel)\n",
    "            filbandwidthsmel = np.linspace(fmelmin, fmelmax, self.out_channels + 2)\n",
    "            filbandwidthsf = self.to_hz(filbandwidthsmel)\n",
    "            self.freq = filbandwidthsf[:self.out_channels]\n",
    "        \n",
    "        self.hsupp = torch.arange(-(self.kernel_size - 1) / 2, (self.kernel_size - 1) / 2 + 1)\n",
    "        self.band_pass = torch.zeros(self.out_channels - 1, self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.freq) - 1):\n",
    "            fmin, fmax = self.freq[i], self.freq[i + 1]\n",
    "            hHigh = (2 * fmax / self.sample_rate) * np.sinc(2 * fmax * self.hsupp.numpy() / self.sample_rate)\n",
    "            hLow = (2 * fmin / self.sample_rate) * np.sinc(2 * fmin * self.hsupp.numpy() / self.sample_rate)\n",
    "            hideal = hHigh - hLow\n",
    "            self.band_pass[i, :] = Tensor(np.hamming(self.kernel_size)) * Tensor(hideal)\n",
    "        \n",
    "        band_pass_filter = self.band_pass.to(self.device)\n",
    "        filters = band_pass_filter.view(self.out_channels - 1, 1, self.kernel_size)\n",
    "        return F.conv1d(x, filters, stride=self.stride, padding=self.padding, dilation=self.dilation)\n",
    "\n",
    "class Residual_block(nn.Module):\n",
    "    def __init__(self, nb_filts, first=False):\n",
    "        super(Residual_block, self).__init__()\n",
    "        self.first = first\n",
    "        if not self.first:\n",
    "            self.bn1 = nn.BatchNorm1d(num_features=nb_filts[0])\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.3)\n",
    "        self.conv1 = nn.Conv1d(nb_filts[0], nb_filts[1], kernel_size=3, padding=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(nb_filts[1])\n",
    "        self.conv2 = nn.Conv1d(nb_filts[1], nb_filts[1], kernel_size=3, padding=1, stride=1)\n",
    "        self.downsample = nb_filts[0] != nb_filts[1]\n",
    "        if self.downsample:\n",
    "            self.conv_downsample = nn.Conv1d(nb_filts[0], nb_filts[1], kernel_size=1, stride=1)\n",
    "        self.mp = nn.MaxPool1d(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.bn1(x) if not self.first else x\n",
    "        out = self.lrelu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.lrelu(out)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            identity = self.conv_downsample(identity)\n",
    "        out += identity\n",
    "        return self.mp(out)\n",
    "\n",
    "class RawNet(nn.Module):\n",
    "    def __init__(self, d_args, device):\n",
    "        super(RawNet, self).__init__()\n",
    "        self.device = device\n",
    "        self.Sinc_conv = SincConv(device=self.device, out_channels=d_args['filts'][0],\n",
    "                                  kernel_size=d_args['first_conv'], in_channels=d_args['in_channels'])\n",
    "        self.first_bn = nn.BatchNorm1d(d_args['filts'][0])\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "        self.block0 = nn.Sequential(Residual_block(nb_filts=d_args['filts'][1], first=True))\n",
    "        self.block1 = nn.Sequential(Residual_block(nb_filts=d_args['filts'][1]))\n",
    "        self.block2 = nn.Sequential(Residual_block(nb_filts=d_args['filts'][2]))\n",
    "        d_args['filts'][2][0] = d_args['filts'][2][1]\n",
    "        self.block3 = nn.Sequential(Residual_block(nb_filts=d_args['filts'][2]))\n",
    "        self.block4 = nn.Sequential(Residual_block(nb_filts=d_args['filts'][2]))\n",
    "        self.block5 = nn.Sequential(Residual_block(nb_filts=d_args['filts'][2]))\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc_attention0 = self._make_attention_fc(d_args['filts'][1][-1], d_args['filts'][1][-1])\n",
    "        self.fc_attention1 = self._make_attention_fc(d_args['filts'][1][-1], d_args['filts'][1][-1])\n",
    "        self.fc_attention2 = self._make_attention_fc(d_args['filts'][2][-1], d_args['filts'][2][-1])\n",
    "        self.fc_attention3 = self._make_attention_fc(d_args['filts'][2][-1], d_args['filts'][2][-1])\n",
    "        self.fc_attention4 = self._make_attention_fc(d_args['filts'][2][-1], d_args['filts'][2][-1])\n",
    "        self.fc_attention5 = self._make_attention_fc(d_args['filts'][2][-1], d_args['filts'][2][-1])\n",
    "        self.bn_before_gru = nn.BatchNorm1d(d_args['filts'][2][-1])\n",
    "        self.gru = nn.GRU(d_args['filts'][2][-1], d_args['gru_node'], num_layers=d_args['nb_gru_layer'], batch_first=True)\n",
    "        self.fc1_gru = nn.Linear(d_args['gru_node'], d_args['nb_fc_node'])\n",
    "        self.fc2_gru = nn.Linear(d_args['nb_fc_node'], d_args['nb_classes'], bias=True)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, y=None, is_test=False):\n",
    "        nb_samp, len_seq = x.shape[0], x.shape[1]\n",
    "        x = x.view(nb_samp, 1, len_seq)\n",
    "        x = self.Sinc_conv(x)\n",
    "        x = F.max_pool1d(torch.abs(x), 3)\n",
    "        x = self.first_bn(x)\n",
    "        x = self.selu(x)\n",
    "        \n",
    "        x0 = self.block0(x)\n",
    "        y0 = self.avgpool(x0).view(x0.size(0), -1)\n",
    "        y0 = self.fc_attention0(y0)\n",
    "        y0 = self.sig(y0).view(y0.size(0), y0.size(1), -1)\n",
    "        x = x0 * y0 + y0\n",
    "\n",
    "        x1 = self.block1(x)\n",
    "        y1 = self.avgpool(x1).view(x1.size(0), -1)\n",
    "        y1 = self.fc_attention1(y1)\n",
    "        y1 = self.sig(y1).view(y1.size(0), y1.size(1), -1)\n",
    "        x = x1 * y1 + y1\n",
    "\n",
    "        x2 = self.block2(x)\n",
    "        y2 = self.avgpool(x2).view(x2.size(0), -1)\n",
    "        y2 = self.fc_attention2(y2)\n",
    "        y2 = self.sig(y2).view(y2.size(0), y2.size(1), -1)\n",
    "        x = x2 * y2 + y2\n",
    "\n",
    "        x3 = self.block3(x)\n",
    "        y3 = self.avgpool(x3).view(x3.size(0), -1)\n",
    "        y3 = self.fc_attention3(y3)\n",
    "        y3 = self.sig(y3).view(y3.size(0), y3.size(1), -1)\n",
    "        x = x3 * y3 + y3\n",
    "\n",
    "        x4 = self.block4(x)\n",
    "        y4 = self.avgpool(x4).view(x4.size(0), -1)\n",
    "        y4 = self.fc_attention4(y4)\n",
    "        y4 = self.sig(y4).view(y4.size(0), y4.size(1), -1)\n",
    "        x = x4 * y4 + y4\n",
    "\n",
    "        x5 = self.block5(x)\n",
    "        y5 = self.avgpool(x5).view(x5.size(0), -1)\n",
    "        y5 = self.fc_attention5(y5)\n",
    "        y5 = self.sig(y5).view(y5.size(0), y5.size(1), -1)\n",
    "        x = x5 * y5 + y5\n",
    "\n",
    "        x = self.bn_before_gru(x)\n",
    "        x = self.selu(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        self.gru.flatten_parameters()\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1_gru(x)\n",
    "        x = self.fc2_gru(x)\n",
    "\n",
    "        return x if not is_test else F.softmax(x, dim=1)\n",
    "\n",
    "    def _make_attention_fc(self, in_features, l_out_features):\n",
    "        return nn.Sequential(nn.Linear(in_features, l_out_features))\n",
    "\n",
    "# ## 3. Dataset Definition\n",
    "# ASVDataset from data_utils_LA.py with augmentations\n",
    "\n",
    "ASVFile = collections.namedtuple('ASVFile', ['speaker_id', 'file_name', 'path', 'sys_id', 'key'])\n",
    "\n",
    "class ASVDataset(Dataset):\n",
    "    def __init__(self, database_path=None, protocols_path=None, transform=None, \n",
    "                 is_train=True, sample_size=None, is_logical=True, feature_name=None, \n",
    "                 is_eval=False, eval_part=0):\n",
    "        track = 'LA'\n",
    "        assert feature_name is not None, 'must provide feature name'\n",
    "        self.track = track\n",
    "        self.is_logical = is_logical\n",
    "        self.prefix = 'ASVspoof2019_{}'.format(track)\n",
    "        self.sysid_dict = {\n",
    "            '-': 0, 'A01': 1, 'A02': 2, 'A03': 3, 'A04': 4, 'A05': 5, 'A06': 6\n",
    "        } if not is_eval else {\n",
    "            '-': 0, 'A07': 1, 'A08': 2, 'A09': 3, 'A10': 4, 'A11': 5, 'A12': 6,\n",
    "            'A13': 7, 'A14': 8, 'A15': 9, 'A16': 10, 'A17': 11, 'A18': 12, 'A19': 13\n",
    "        }\n",
    "        self.data_root_dir = database_path\n",
    "        self.is_eval = is_eval\n",
    "        self.sysid_dict_inv = {v: k for k, v in self.sysid_dict.items()}\n",
    "        self.data_root = protocols_path\n",
    "        self.dset_name = 'eval' if is_eval else 'train' if is_train else 'dev'\n",
    "        self.protocols_fname = 'eval.trl' if is_eval else 'train.trn' if is_train else 'dev.trl'\n",
    "        self.protocols_dir = os.path.join(self.data_root)\n",
    "        self.files_dir = os.path.join(self.data_root_dir, f'{self.prefix}_{self.dset_name}', 'flac')\n",
    "        self.protocols_fname = os.path.join(self.protocols_dir, f'ASVspoof2019.{track}.cm.{self.protocols_fname}.txt')\n",
    "        self.cache_fname = f'cache_{self.dset_name}_{track}_{feature_name}.npy'\n",
    "        self.transform = transform\n",
    "\n",
    "        if os.path.exists(self.cache_fname):\n",
    "            self.data_x, self.data_y, self.data_sysid, self.files_meta = torch.load(self.cache_fname)\n",
    "            print(f'Dataset loaded from cache {self.cache_fname}')\n",
    "        else:\n",
    "            self.files_meta = self.parse_protocols_file(self.protocols_fname)\n",
    "            data = list(map(self.read_file, self.files_meta))\n",
    "            self.data_x, self.data_y, self.data_sysid = map(list, zip(*data))\n",
    "            if self.transform:\n",
    "                self.data_x = Parallel(n_jobs=4, prefer='threads')(delayed(self.transform)(x) for x in self.data_x)\n",
    "            torch.save((self.data_x, self.data_y, self.data_sysid, self.files_meta), self.cache_fname)\n",
    "        \n",
    "        if sample_size:\n",
    "            select_idx = np.random.choice(len(self.files_meta), size=(sample_size,), replace=True).astype(np.int32)\n",
    "            self.files_meta = [self.files_meta[x] for x in select_idx]\n",
    "            self.data_x = [self.data_x[x] for x in select_idx]\n",
    "            self.data_y = [self.data_y[x] for x in select_idx]\n",
    "            self.data_sysid = [self.data_sysid[x] for x in select_idx]\n",
    "        \n",
    "        self.length = len(self.data_x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data_x[idx]\n",
    "        y = self.data_y[idx]\n",
    "        # Channel augmentation: Simulate stereo\n",
    "        if np.random.rand() > 0.5:\n",
    "            x_stereo = np.stack([x, np.roll(x, 10)])\n",
    "            x = x_stereo.mean(axis=0)\n",
    "        # Compression augmentation: Add noise\n",
    "        if np.random.rand() > 0.5:\n",
    "            x += np.random.randn(*x.shape) * 0.01\n",
    "        return x, y, self.files_meta[idx]\n",
    "\n",
    "    def read_file(self, meta):\n",
    "        data_x, sample_rate = sf.read(meta.path)\n",
    "        data_y = meta.key\n",
    "        return data_x, float(data_y), meta.sys_id\n",
    "\n",
    "    def _parse_line(self, line):\n",
    "        tokens = line.strip().split(' ')\n",
    "        return ASVFile(speaker_id=tokens[0], file_name=tokens[1],\n",
    "                       path=os.path.join(self.files_dir, tokens[1] + '.flac'),\n",
    "                       sys_id=self.sysid_dict[tokens[3]], key=int(tokens[4] == 'bonafide'))\n",
    "\n",
    "    def parse_protocols_file(self, protocols_fname):\n",
    "        lines = open(protocols_fname).readlines()\n",
    "        return list(map(self._parse_line, lines))\n",
    "\n",
    "# ## 4. Training and Evaluation Functions\n",
    "# From provided training script\n",
    "\n",
    "def pad(x, max_len=64600):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    return padded_x\n",
    "\n",
    "def evaluate_accuracy(data_loader, model, device):\n",
    "    num_correct = 0.0\n",
    "    num_total = 0.0\n",
    "    model.eval()\n",
    "    for batch_x, batch_y, batch_meta in data_loader:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        batch_out = model(batch_x, batch_y)\n",
    "        _, batch_pred = batch_out.max(dim=1)\n",
    "        num_correct += (batch_pred == batch_y).sum(dim=0).item()\n",
    "    return 100 * (num_correct / num_total)\n",
    "\n",
    "def train_epoch(data_loader, model, lr, optim, device):\n",
    "    running_loss = 0\n",
    "    num_correct = 0.0\n",
    "    num_total = 0.0\n",
    "    model.train()\n",
    "    weight = torch.FloatTensor([1.0, 9.0]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    \n",
    "    for batch_x, batch_y, batch_meta in data_loader:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        batch_out = model(batch_x, batch_y)\n",
    "        batch_loss = criterion(batch_out, batch_y)\n",
    "        _, batch_pred = batch_out.max(dim=1)\n",
    "        num_correct += (batch_pred == batch_y).sum(dim=0).item()\n",
    "        running_loss += (batch_loss.item() * batch_size)\n",
    "        optim.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    running_loss /= num_total\n",
    "    train_accuracy = (num_correct / num_total) * 100\n",
    "    return running_loss, train_accuracy\n",
    "\n",
    "# ## 5. Main Execution\n",
    "# Model config, data loading, training, and evaluation\n",
    "\n",
    "# Model configuration (example from RawNet2 literature)\n",
    "d_args = {\n",
    "    'filts': [20, [20, 20], [20, 128], [128, 128]],\n",
    "    'first_conv': 251,\n",
    "    'in_channels': 1,\n",
    "    'gru_node': 1024,\n",
    "    'nb_gru_layer': 1,\n",
    "    'nb_fc_node': 1024,\n",
    "    'nb_classes': 2\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = RawNet(d_args, device).to(device)\n",
    "\n",
    "# Data loading (replace paths with your ASVspoof 5 locations)\n",
    "database_path = '/path/to/ASVspoof5/'\n",
    "protocols_path = '/path/to/ASVspoof5/protocols/'\n",
    "transform = transforms.Compose([lambda x: pad(x), lambda x: Tensor(x)])\n",
    "train_set = ASVDataset(database_path=database_path, protocols_path=protocols_path, \n",
    "                       transform=transform, is_train=True, sample_size=1000, \n",
    "                       is_logical=True, feature_name='Raw_audio')\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "dev_set = ASVDataset(database_path=database_path, protocols_path=protocols_path, \n",
    "                     transform=transform, is_train=False, sample_size=1000, \n",
    "                     is_logical=True, feature_name='Raw_audio')\n",
    "dev_loader = DataLoader(dev_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "num_epochs = 5  # Light fine-tuning\n",
    "writer = SummaryWriter('logs/rawnet2_momenta')\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss, train_accuracy = train_epoch(train_loader, model, 0.0001, optimizer, device)\n",
    "    valid_accuracy = evaluate_accuracy(dev_loader, model, device)\n",
    "    losses.append(running_loss)\n",
    "    writer.add_scalar('train_accuracy', train_accuracy, epoch)\n",
    "    writer.add_scalar('valid_accuracy', valid_accuracy, epoch)\n",
    "    writer.add_scalar('loss', running_loss, epoch)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Loss: {running_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Dev Acc: {valid_accuracy:.2f}%')\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "torch.save(model.state_dict(), 'models/rawnet2_epoch_5.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
